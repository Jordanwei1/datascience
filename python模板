[python] view plain copy

#基础模板
title="""
     原样输出大法
 python基础模板
 pythonsklearn模板
 pythonpandas模板
 pythonnumpy模板
 pythonmatplolib模板
"""
# 基本类型和运算符
# 定义了一个数字 3
3  # => 3

# 基本计算
1 + 1  # => 2
8 - 1  # => 7
10 * 2  # => 20
35 / 5  # => 7

# 当除数和被除数都为整型时，除 这个操作只求整数
# ( python2.x语法。经测试，Python3.x 已经全部当做浮点数处理,还会计算小数)
5 / 2  # => 2
10 / -3  # python3的结果为-3.3333333333333335 python2 结果为-4
10 / 3  # python3的结果为3.3333333333333335 python2 结果为3
# 由上面两个结果也可以看出，在Python2中，如结果有小数，则会取最近最小整数


# 如果我们除数和被除数为浮点型，则Python会自动把结果保存为浮点数
2.0  # 这是浮点数
11.0 / 4.0  # 这个时候结果就是2.75啦！是不是很神奇？

# 当用‘//’进行计算时，python3不会全部单做浮点数处理.
5 // 3  # => 1
5.0 // 3.0  # => 1.0
-5 // 3  # => -2
-5.0 // 3.0  # => -2.0

from __future__ import division  # 注可以在通过 __future__  关键字

# 在python2中引入python3 特性
11 / 4  # => 2.75  ... 标准除法
11 // 4  # => 2 ... 除后取整

# 求余数操作
7 % 3  # => 1

# 幂操作 2的4次方
2 ** 4  # => 16

# 先乘除，后加减，口号优先
(1 + 3) * 2  # => 8

# 布尔值操作
# 注：or 和 and 两个关键字是大小写敏感的
True and False  # => 返回False
False or True  # => 返回True

# 布尔值和整形的关系，除了0外，其他都为真
0 and 2  # => 0
-5 or 0  # => -5
0 == False  # => True
2 == True  # => False
1 == True  # => True

#  not 操作
not True  # => False
not False  # => True

# 等值比较 “==”，相等返回值为True ，不相等返回False
1 == 1  # => True
2 == 1  # => False

# 非等比较“！=”，如果两个数不相等返回True，相等返回Flase
1 != 1  # => False
2 != 1  # => True

# 大于/小于 和等于的组合比较
1 < 10  # => True
1 > 10  # => False
2 <= 2  # => True
2 >= 2  # => True

# Python可以支持多数值进行组合比较，
# 但只要一个等值为False，则结果为False
1 < 2 < 3  # => True
2 < 3 < 2  # => False

# 可以通过 " 或者 '来创建字符串
"This is a string."
'This is also a string.'

# 字符串间可以通过 + 号进行相加，是不是简单到爆？
"Hello " + "world!"  # => "Hello world!"
# 甚至不使用'+'号，也可以把字符串进行连接
"Hello " "world!"  # => "Hello world!"

# 可以通过 * 号，对字符串进行复制，比如 ；
importantNote = "重要的事情说三遍\n" * 3
print （importantNote）
""" 结果为：
 重要的事情说三遍
 重要的事情说三遍
 重要的事情说三遍
"""

"Hello" * 3  # => "HelloHelloHello"

# 字符串可以在任意位置被打断
"This is a string"[0]  # => 'T'

# 字符串可以用 %连接，并且可以打印出变量值
# （和C/C++ 一样%d 表示整数，%s表示字符串，
# 但python可以自己进行判断，我们无需太担心这个问题）
x = 'apple'
y = 'lemon'
z = "The items in the basket are %s and %s" % (x, y)

# 一个新的更好的字符串连接方式是通过.format()函数，推荐使用该方式
"{} is a {}".format("This", "placeholder")
"{0} can be {1}".format("strings", "formatted")
# You can use keywords if you don't want to count.
"{name} wants to eat {food}".format(name="Bob", food="lasagna")

# None是一个对象,None就是None，它是一个特殊的变量
None  # => None

# 在和None进行比较时，不要用“==”操作符，用 “is”
"etc" is None  # => False
None is None  # => True

# “is"操作符用于对象之间的比较，
# 对于底层类型进行比较时
# 不建议用“is”，但对于对象之间的比较，用“is”是最合适的
# bool可以用于对任何对象进行判断
# 以下这些值是非真的
#   - None
#   - 各类数值型的0 (e.g., 0, 0L, 0.0, 0j)
#   - 空元组、空列表 (e.g., '', (), [])
#   - 空字典、空集合 (e.g., {}, set())
#   - 其他值请参考：
#     https://docs.python.org/2/reference/datamodel.html#object.__nonzero__
#
# All other values are truthy (using the bool() function on them returns True).
bool(0)  # => False
bool("")  # => False

# 变量和集合
# 打印 print()
print("I'm Python. Nice to meet you!")  # => I'm Python. Nice to meet you!

# 从控制台中获取输入
input_string_var = raw_input("Enter some data: ")  # 返回字符串类型
input_var = input("Enter some data: ")  # python会判断类型如果是字符串 则输入时要加“”or''
# 注意：在 python 3中, input() 由 raw_input() 代替

# 在Python中不需要设定变量类型，python会自动根据值进行判断
some_var = 5
some_var  # => 5

# if 可以作为表达时被使用,下句可以这样理解 “输出‘yahool’如果3大于2的话，不然输出2“
"yahoo!" if 3 > 2 else 2  # => "yahoo!"

#列表
# python中的列表定义
li = []
# 也可以通过初始化时内置列表的值
other_li = [4, 5, 6]

# append函数可以在列表中插入值
li.append(1)  # li is now [1]
li.append(2)  # li is now [1, 2]
li.append(4)  # li is now [1, 2, 4]
li.append(3)  # li is now [1, 2, 4, 3]
# pop函数从列表末移除值
li.pop()  # => 3 and li is now [1, 2, 4]
# 移除后通过append接回
li.append(3)  # li is now [1, 2, 4, 3] again.

# 通过[]的方式可以提取任何列表中的任意值
# （前提，index不大于列表总数）
li[0]  # => 1
# 也可以通过[]下标的方式直接给列表赋值
li[0] = 42
li[0]  # => 42
# 如果[]小标的值为负数，则表示以逆序获取列表中的值
li[-1]  # => 3

# 查询的值不可以超出列表个数，否则报错。
# 但是利用insert()插入时可以，超出范围的值会直接被插入到列表最末
li[4]  # Raises an IndexError

# 可以通过[:],获取列表中指定范围的值
# (It's a closed/open range for you mathy types.)
# 这是半开取值法，比如li[1:3],取的是列表中index为1、2的两个值，
# 该法则适用于以下所有通过[]取值的方式
li[1:3]  # => [2, 4]
# 如果一边不去值，则表示取所有该边的值。
li[2:]  # => [4, 3]
li[:3]  # => [1, 2, 4]

# [::2]表示选择从[0]开始，步长为2上的值
li[::2]  # =>[1, 4]
# [::-1]表示反向选择，-可以理解为 反向选择，而1表示步长，步长1则包含了列表中的所有元素
li[::-1]  # => [3, 4, 2, 1]
# []规则完整版表示方法[开始：结束：步长]
# li[start:end:step]

#  "del"关键字可以直接删除列表中的值
del li[2]  # li is now [1, 2, 3]

# 可以通过“+”操作符对列表进行操作,注：列表只有 + 操作，而集合（set）有+ 和 -
li + other_li  # => [1, 2, 3, 4, 5, 6]

# 也可以 "extend()"方法对列表进行扩展
li.extend(other_li)  # Now li is [1, 2, 3, 4, 5, 6]

# Remove 方法和 del 类似，但remove的直接是数值，而不是index
li.remove(2)  # li is now [1, 3, 4, 5, 6]
li.remove(2)  # 如果remove的值不存在列表中，则会报错

# 在指定位置插入数值，上面已经提过，如果index值超过的话，会直接插到列表末
li.insert(1, 2)  # li is now [1, 2, 3, 4, 5, 6] again

# 获取某个值的index
li.index(2)  # => 1
li.index(7)  # 如果

# "in"可以直接查看某个值是否存在于列表中
1 in li  # => True

# "len()"函数可以检测队列的数量
len(li)  # => 6

# 元祖
# Tuples(元组）是一个类似数列的数据结构，但是元组是不可修改的
tup = (1, 2, 3)
tup[0]  # => 1
tup[0] = 3  # 一修改就会报错

# 数列中的方法在元组也可以使用（除了 修改）
len(tup)  # => 3
tup + (4, 5, 6)  # => (1, 2, 3, 4, 5, 6)
tup[:2]  # => (1, 2)
2 in tup  # => True

# 可以一次性赋值几个变量
a, b, c = (1, 2, 3)  # a 为1，b为2，c为3
d, e, f = 4, 5, 6  # 元组赋值也可以不用括号
# 同样元组不用括号也同样可以创建
g = 4, 5, 6  # => (4, 5, 6)
# Python中的数据交换十分简单：只要在赋值时互调位置即可
e, d = d, e  # d is now 5 and e is now 4

# 字典
# Python中的字典定义
empty_dict = {}
# 也可以通过定义时赋值给字典
filled_dict = {"one": 1, "two": 2, "three": 3}

# 可以通过[]的key方式查询字典中的值
filled_dict["one"]  # => 1

# 可以通过"keys()"方法获取字典中的所有key值
filled_dict.keys()  # => ["three", "two", "one"]
# Note - 返回的keys并不一定按照顺序排列的.
# 所以测试结果可能和上述结果不一致

# 通过 "values()"的方式可以获取字典中所有值，
# 同样他们返回的结果也不一定按照顺序排列
filled_dict.values()  # => [3, 2, 1]

# 可以通过 "in"方式获取查询某个键值是否存在字典中，但是数值不可以
"one" in filled_dict  # => True
1 in filled_dict  # => False

# 查找不存在的key值时，Python会报错
filled_dict["four"]  # KeyError

# 用 "get()" 方法可以避免键值错误的产生
filled_dict.get("one")  # => 1
filled_dict.get("four")  # => None
# 当键值不存在的时候，get方法可以通过返回默认值，
# 但是并没有对值字典进行赋值
filled_dict.get("one", 4)  # => 1
filled_dict.get("four", 4)  # => 4

# 字典中设置值的方式和列表类似，通过[]方式可以设置
filled_dict["four"] = 4  # now, filled_dict["four"] => 4

# "setdefault()" 可以设置字典中的值
# 但是注意：只有当该键值之前未存在的时候，setdefault（）函数才生效
filled_dict.setdefault("five", 5)  # filled_dict["five"] is set to 5
filled_dict.setdefault("five", 6)  # filled_dict["five"] is still 5

# 集合
empty_set = set()
# 初始化set的方式可以通过 set()来实现
some_set = set([1, 2, 2, 3, 4])  # some_set is now set([1, 2, 3, 4])

# 集合的排列是无序的！集合的排列是无序的！集合的排列是无序的！
another_set = set([4, 3, 2, 2, 1])  # another_set is now set([1, 2, 3, 4])

# Python2.7以后，{}可以用于被定义集合
filled_set = {1, 2, 2, 3, 4}  # => {1, 2, 3, 4}

# Add方法可用于增加集合成员
filled_set.add(5)  # filled_set is now {1, 2, 3, 4, 5}

# 集合可通过 &操作符取交集
other_set = {3, 4, 5, 6}
filled_set & other_set  # => {3, 4, 5}

# 通过|操作符取并集
filled_set | other_set  # => {1, 2, 3, 4, 5, 6}

# 通过 - 操作符取差集
{1, 2, 3, 4} - {2, 3, 5}  # => {1, 4}

# 通过 ^ 操作符取非集
{1, 2, 3, 4} ^ {2, 3, 5}  # => {1, 4, 5}

# 通过 >= 判断左边集合是否是右边集合的超集
{1, 2} >= {1, 2, 3}  # => False

# 通过 <= 判断左边集合是否右边集合的子集
{1, 2} <= {1, 2, 3}  # => True

# 通过 in 可以判断元素是否在集合中
2 in filled_set  # => True
10 in filled_set  # => False

# Python数据集合类型总结
conclusion1="""
列表 定义方式 li = [1,2,3,4，“Hello World”] （列表可以包含任意基本类型）
元组 定义方式 tup = (1,2,3,4) （和列表类似，但 元组不可更改）
字典 定义方式 dic = {“one”：2，“tow”：3，“three”：0}（字典，就是字典嘛。以 key:value 方式存在）
集合 定义方式 set=set（1，2，3，4）or set = {1，2，3，4} （集合里的元素是唯一的，集合支持 & | ^ + -操作）

"""
#Python 逻辑运算符
# 创建一个变量
some_var = 5

# 通过if进行逻辑判断
if some_var > 10:
    print
    "some_var is totally bigger than 10."
elif some_var < 10:  # This elif clause is optional.
    print
    "some_var is smaller than 10."
else:  # This is optional too.
    print
    "some_var is indeed 10."

"""
    通过for...in...进行循环打印：
    dog is a mammal
    cat is a mammal
    mouse is a mammal
"""
for animal in ["dog", "cat", "mouse"]:
    # You can use {0} to interpolate formatted strings. (See above.)
    print
    "{0} is a mammal".format(animal)

"""
通过"range()" 方式，控制for的循环次数
prints:
    0
    1
    2
    3
"""
for i in range(4):
    print
    i

"""
"range(lower, upper)" 返回 lower 到 upper的值,
 注意：range左边必须小于右边参数
prints:
    4
    5
    6
    7
"""
for i in range(4, 8):
    print
    i

"""
while 循环
prints:
    0
    1
    2
    3
"""
x = 0
while x < 4:
    print
    x
    x += 1  # Shorthand for x = x + 1

# Python支持 try/except 语法

# Python2.6以上的版本，支持try...except...:
try:
    # raise显示地引发异常。一旦执行了raise语句，raise后面的语句将不能执行。
    raise IndexError("This is an index error")
except IndexError as e:
    pass  # pass 空语句，跳过处理
except (TypeError, NameError):
    pass  # python 支持同时检测多个错误
else:  # Python必须要处理所有情况，这里是其他未定义的情况
    print
    "All good!"
finally:  # finally无论有没有异常都会执行
    print
    "We can clean up resources here"

# 通过with函数，可以替代try....except...函数  [with详解](http://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/)
with open("myfile.txt") as f:
    for line in f:
        print
        line
# 函数Functions
    # def 关键字定义函数
    def add(x, y):
        print
        "x is {0} and y is {1}".format(x, y)
        return x + y  # 可以直接return结果


    # 函数调用参数
    add(5, 6)  # => prints out "x is 5 and y is 6" and returns 11

    # Python支持参数互换，只需要在调用函数时加上形参
    add(y=6, x=5)  # Keyword arguments can arrive in any order.


    # Python函数支持可变参数
    #  在定义函数时通过*号表示可变长参数
    def varargs(*args):
        return args


    varargs(1, 2, 3)  # => (1, 2, 3)


    # 可以通过**的方式定义Key可变长参数查找字典中的关键词

    def keyword_args(**kwargs):
        return kwargs


    # 当函数参数是**类型的时候，Python可以通过该函数定义字典
    keyword_args(big="foot", loch="ness")  # => {"big": "foot", "loch": "ness"}


    # 同时支持函数和字典类型参数，具体事例如下：
    def all_the_args(*args, **kwargs):
        print
        args
        print
        kwargs


    """
    all_the_args(1, 2, a=3, b=4) prints:
        (1, 2)
        {"a": 3, "b": 4}
    """

    # 在调用函数时，可以同时赋值，文字难以表达，例子如下：
    args = (1, 2, 3, 4)
    kwargs = {"a": 3, "b": 4}
    all_the_args(*args)  # equivalent to foo(1, 2, 3, 4)
    all_the_args(**kwargs)  # equivalent to foo(a=3, b=4)
    all_the_args(*args, **kwargs)  # equivalent to foo(1, 2, 3, 4, a=3, b=4)


    # 在函数中也可以通过单独处理* 或者 **的方式，增加函数的健壮性
    def pass_all_the_args(*args, **kwargs):
        all_the_args(*args, **kwargs)
        print
        varargs(*args)
        print
        keyword_args(**kwargs)


    # 全局变量 X
    x = 5


    def set_x(num):
        # 当在函数里面改变变量时，如果没有加gloabl关键字，则改变的是局部变量
        x = num  # => 43
        print
        x  # => 43


    def set_global_x(num):
        global x
        print
        x  # => 5
        x = num  # 加了global关键字后，即可在函数内操作全局变量
        print
        x  # => 6


    set_x(43)
    set_global_x(6)


    # 返回函数指针方式定义函数/*换个说法，匿名函数*/
    def create_adder(x):
        def adder(y):
            return x + y

        return adder


    add_10 = create_adder(10)
    add_10(3)  # => 13

    # Lambda 关键字定义的匿名函数
    (lambda x: x > 2)(3)  # => True
    (lambda x, y: x ** 2 + y ** 2)(2, 1)  # => 5

    # map方式也可以调用函数并传入参数
    map(add_10, [1, 2, 3])  # => [11, 12, 13]
    map(max, [1, 2, 3], [4, 2, 1])  # => [4, 2, 3]

    filter(lambda x: x > 5, [3, 4, 5, 6, 7])  # => [6, 7]

    # 可以通过这两种方式结合调用，下面的函数解析：
    # add_10(i) 是映射了for...in...函数的返回值，返回值作为参数传进。
    [add_10(i) for i in [1, 2, 3]]  # => [11, 12, 13]
    [x for x in [3, 4, 5, 6, 7] if x > 5]  # => [6, 7]

#Python中的类
    # 下面代码是定义了一个Human类，继承自object类
    # Python类可以继承自多个类，如class Human(object,orangOutang)
    class Human(object):
        # 类变量
        species = "H. sapiens"
        类接口
        __species = "Other.sapiens"  # 内部结构，无法被外部直接访问


    # __init__(),初始化函数，python中在对类进行处理时，会先处理以下函数，
    # 其实就是系统默认定义了接口，而这个接口是开放给用户去实现的，具体如下：
    # __init__  构造函数，在生成对象时调用
    # __del__   析构函数，释放对象时使用
    # __repr__ 打印，转换
    # __setitem__按照索引赋值
    # __getitem__按照索引获取值
    # __len__获得长度
    # __cmp__比较运算
    # __call__函数调用
    # __add__加运算
    # __sub__减运算
    # __mul__乘运算
    # __div__除运算
    # __mod__求余运算
    # __pow__称方

    def __init__(self, name):
        # 声明类中的属性，并初始化，在初始化的时候同时
        # 就是定义了变量类型
        self.name = name
        self.age = 0


    # 在类中所有函数都必须把self作为第一个参数
    # （下面定义的类方法和静态方法除外）
    def say(self, msg):
        return "{0}: {1}".format(self.name, msg)


    # 类方法
    @classmethod
    def get_species(cls):
        return cls.species


    # 静态方法，
    @staticmethod
    def grunt():
        return "*grunt*"


    # A property is just like a getter.
    # It turns the method age() into an read-only attribute
    # of the same name.
    # property属性，相当于getter
    @property
    def age(self):
        return self._age


    # This allows the property to be set
    @age.setter
    def age(self, age):
        self._age = age


    # This allows the property to be deleted
    @age.deleter
    def age(self):
        del self._age

# 类实例化
i = Human(name="Ian")
print
i.say("hi")  # prints out "Ian: hi"

j = Human("Joel")
print
j.say("hello")  # prints out "Joel: hello"

# 调用实例方法用"."
i.get_species()  # => "H. sapiens"

# 改变类变量
Human.species = "H. neanderthalensis"
i.get_species()  # => "H. neanderthalensis"
j.get_species()  # => "H. neanderthalensis"

# 调用静态方法
Human.grunt()  # => "*grunt*"

# 给age赋值
i.age = 42

# 获取age值
i.age  # => 42

# 删除age
del i.age
i.age  # => raises an AttributeError

# 模块 Python的模块（库）
# Python中的一个*.py文件就是一个模块
import math

print
math.sqrt(16)  # => 4

# 可以只引入模块中的某些类/方法
from math import ceil, floor

print
ceil(3.7)  # => 4.0
print
floor(3.7)  # => 3.0

# 也可以通过*引入全部方法
# Warning: this is not recommended
from math import *

# math库的缩写可以为m
math.sqrt(16) == m.sqrt(16)  # => True
# 可以直接引入sqrt库
from math import sqrt

math.sqrt == m.sqrt == sqrt  # => True

# python的库就只是文件
import math

dir(math)

# If you have a Python script named math.py in the same
# folder as your current script, the file math.py will
# be loaded instead of the built-in Python module.
# This happens because the local folder has priority
# over Python's built-in libraries.

# 如果你在当前目录下有一个Python脚本的名字也叫math.py
# 当前目录下的math.py会替换掉内置的Python模块
# 因为在Python中当前目录的优先级会高于内置模块的优先级

#Python中的高级特性（生成器、装饰器:wraps）
# Generators ，生成器函数在Python中与迭代器协议的概念联系在一起。
# 简而言之，包含yield语句的函数会被特地编译成生成器。
# 当函数被调用时，他们返回一个生成器对象，这个对象支持迭代器接口。函数
# 也许会有个return语句，但它的作用是用来yield产生值的。
for i in iterable:
    yield i + i

xrange_ = xrange(1, 900000000)

for i in double_numbers(xrange_):
    print
    i
    if i >= 30:
        break

# 装饰器wraps，wraps可以包装
# Beg will call say. If say_please is True then it will change the returned
# message
from functools import wraps


def beg(target_function):
    @wraps(target_function)
    def wrapper(*args, **kwargs):
        msg, say_please = target_function(*args, **kwargs)
        if say_please:
            return "{} {}".format(msg, "Please! I am poor :(")
        return msg

    return wrapper


@beg
def say(say_please=False):
    msg = "Can you buy me a beer?"
    return msg, say_please


print
say()  # Can you buy me a beer?
print
say(say_please=True)  # Can you buy me a beer? Please! I am poor :



#算法模板
title="""
人工智能 内核就是 机器学习 内核就是 算法 
程序=数据结构+算法 作文=词语+语法
三大基石，数据 软件工程师 模型 数据科学家 算力 硬件工程师

常见的问题类型只有三种：分类、回归、聚类。而明确具体问题对应的类型也很简单。
分类：

回归：

聚类：


比如，如果你需要通过输入数据得到一个类别变量，那就是分类问题。
分成两类就是二分类问题，分成两类以上就是多分类问题。
常见的有：判别一个邮件是否是垃圾邮件、根据图片分辩图片里的是猫还是狗等等。
如果你需要通过输入数据得到一个具体的连续数值，那就是回归问题。
比如：预测某个区域的房价等。
常用的分类和回归算法算法有：
SVM (支持向量机) 、xgboost、, KNN、LR算法、SGD (随机梯度下降算法)、
Bayes (贝叶斯估计)以及随机森林等。这些算法大多都既可以解分类问题，又可以解回归问题。

如果你的数据集并没有对应的属性标签，你要做的，是发掘这组样本在空间的分布, 
比如分析哪些样本靠的更近，哪些样本之间离得很远, 这就是属于聚类问题。
常用的聚类算法有k-means算法。

在本文中，我们主要解决第二步：通过skicit-learn构建模型。
告诉你你一套让你简单到想笑的通用模型构建模板。
只要scikit-learn实现的算法，都可以通过这种方式快速调用。
牢记这三个万能模板，你就能轻松构建起自己的机器学习模型。
"""
#万能模板
exampleW="""
from sklearn.算法位置 import 算法名
from sklearn.metrics import accuracy_score #用于精确度评估模型
#生成一个模型对象
模型名 = 算法名（模型参数【选填】）
#训练模型
模型名.fit(train_x,train_y)
#在训练集上评估模型
pred1 = 模型名.predict(train_x)
accuracy1 = accuracy_score(train_y,pred1)
print('在训练集上的精确度: %.4f'%accuracy1)
#在测试集上评估模型
pred2 = 模型名.predict(test_x)
accuracy2 = accuracy_score(test_y,pred2)
print('在测试集上的精确度: %.4f'%accuracy2)
"""

# 加载数据集
#在scikit-learn下的datasets子包里，也自带了一个Iris数据集，
# 这个数据集和原始数据集的区别就是scikit-learn已经帮我们提前处理好了空值等问题，
# 可以直接输入模型用来训练。所以为了方便起见，我们直接使用scikit-learn的数据集。
from sklearn.datasets import load_iris
data = load_iris()
x = data.data
y = data.target
#数据集拆分
#数据集拆分是为了验证模型在训练集和测试集是否过拟合，
# 使用train_test_split的目的是保证从数据集中均匀拆分出测试集。
# 这里，简单把10%的数据集拿出来用作测试集。
from sklearn.model_selection import train_test_split
train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.1,random_state=0)
#构建SVM分类模型
# 通过查阅资料，我们知道svm算法在scikit-learn.svm.SVC下，所以：
# 算法位置填入：svm
# 算法名填入：SVC()
# 模型名自己起，这里我们就叫svm_model
# 套用模板得到程序如下：
SVM1="""
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

svm_model = SVC()

svm_model.fit(train_x, train_y)

pred1 = svm_model.predict(train_x)
accuracy1 = accuracy_score(train_y, pred1)
print('在训练集上的精确度: %.4f' % accuracy1)

pred2 = svm_model.predict(test_x)
accuracy2 = accuracy_score(test_y, pred2)
print('在测试集上的精确度: %.4f' % accuracy2)
"""
# 构建LR分类模型
# 同理，找到LR算法在sklearn.linear_model.LogisticRegression下，所以：
# 算法位置填入：linear_model
# 算法名填入：LogisticRegression
# 模型名叫做：lr_model。

LR1="""
# LogisticRegression分类器

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score  # 评分函数用精确度评估

lr_model = LogisticRegression()

lr_model.fit(train_x, train_y)

pred1 = lr_model.predict(train_x)
accuracy1 = accuracy_score(train_y, pred1)
print('在训练集上的精确度: %.4f' % accuracy1)

pred2 = lr_model.predict(test_x)
accuracy2 = accuracy_score(test_y, pred2)
print('在测试集上的精确度: %.4f' % accuracy2)
"""

#万能模板2
exampleW2="""
万能模板V2.0版
加入交叉验证，让算法模型评估更加科学
在1.0版的模板中，当你多次运行同一个程序就会发现：每次运行得到的精确度并不相同，
而是在一定范围内浮动，这是因为数据输入模型之前会进行选择，
每次训练时数据输入模型的顺序都不一样。所以即使是同一个程序，模型最后的表现也会有好有坏。
更糟糕的是，有些情况下，在训练集上，通过调整参数设置使模型的性能达到了最佳状态，
但在测试集上却可能出现过拟合的情况。这个时候，我们在训练集上得到的评分不能有效反映出模型的泛化性能。
为了解决上述两个问题，还应该在训练集上划分出验证集(validation set)并结合交叉验证来解决。
首先，在训练集中划分出不参与训练的验证集，只是在模型训练完成以后对模型进行评估，
接着再在测试集上进行最后的评估。
但这样大大减少了可用于模型学习的样本数量，所以还需要采用交叉验证的方式多训练几次。
比如说最常用的k-折交叉验证如下图所示，它主要是将训练集划分为 k 个较小的集合。
然后将k-1份训练子集作为训练集训练模型，将剩余的 1 份训练集子集作为验证集用于模型验证。
这样需要训练k次，最后在训练集上的评估得分取所有训练结果评估得分的平均值。
这样一方面可以让训练集的所有数据都参与训练，另一方面也通过多次计算得到了一个比较有代表性的得分。唯一的缺点就是计算代价很高，增加了k倍的计算量。
原理就是这样，但理想很丰满，现实很骨干。
在自己实现的时候却有一个很大的难题摆在面前：怎么能够把训练集均匀地划分为K份？
这个问题不用思考太多，既然别忘了，我们现在是站在巨人的肩膀上，
scikit-learn已经将优秀的数学家所想到的均匀拆分方法和程序员的智慧融合在了cross_val_score() 
这个函数里了，只需要调用该函数即可，不需要自己想什么拆分算法，也不用写for循环进行循环训练。

from sklearn.算法位置 import 算法名
from sklearn.metrics import accuracy_score #用于精确度评估模型
#生成一个模型对象
模型名 = 算法名（模型参数【选填】）
#训练模型
模型名.fit(train_x,train_y) 
scores1 = cross_val_score(模型名,train_x,train_y,cv=n,scoring='accuracy')
# 输出精确度的平均值
# print("训练集上的精确度: %0.2f " % scores1.mean())
# 输出精确度的平均值和置信度区间
print("训练集上的平均精确度: %0.2f (+/- %0.2f)" % (scores2.mean(), scores2.std() * 2))
scores2 = cross_val_score(模型名,test_x,test_y,cv=n,scoring='accuracy')
# print("测试集上的精确度: %0.2f " % scores1.mean())
"""

#构建SVM分类模型

### svm分类器

SVM2="""from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC

svm_model = SVC()
svm_model.fit(train_x, train_y)

scores1 = cross_val_score(svm_model, train_x, train_y, cv=5, scoring='accuracy')
# 输出精确度的平均值和置信度区间
print("训练集上的精确度: %0.2f (+/- %0.2f)" % (scores1.mean(), scores1.std() * 2))

scores2 = cross_val_score(svm_model, test_x, test_y, cv=5, scoring='accuracy')
# 输出精确度的平均值和置信度区间
print("测试集上的平均精确度: %0.2f (+/- %0.2f)" % (scores2.mean(), scores2.std() * 2))

print(scores1)
print(scores2)"""

# LogisticRegression分类器
#注： 如果想要一次性评估多个指标，也可以使用可以一次性输入多个评估指标的 cross_validate()函数。
LR2="""from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression()
lr_model.fit(train_x, train_y)

scores1 = cross_val_score(lr_model, train_x, train_y, cv=5, scoring='accuracy')
# 输出精确度的平均值和置信度区间
print("训练集上的精确度: %0.2f (+/- %0.2f)" % (scores1.mean(), scores1.std() * 2))

scores2 = cross_val_score(lr_model, test_x, test_y, cv=5, scoring='accuracy')
# 输出精确度的平均值和置信度区间
print("测试集上的平均精确度: %0.2f (+/- %0.2f)" % (scores2.mean(), scores2.std() * 2))

print(scores1)
print(scores2)"""

#万能模板3
exampleW3="""
调参让算法表现更上一层楼
以上都是通过算法的默认参数来训练模型的，不同的数据集适用的参数难免会不一样，
自己设计算法是设计不来的，只能调调参这样子，调参，是广大算法工程师最后的尊严。
再说，若是做算法不调参，岂不是辱没了算法工程师在江湖上大名鼎鼎的“炼丹工程师”的名声？
scikit-learn对于不同的算法也提供了不同的参数可以自己调节。
如果细说起来，又能写好几篇文章，本文目的是构建一个万能算法框架构建模板，
所以，这里只介绍一下一个通用的自动化调参方法，
至于更细节的每个算法对应参数的含义以及手动调参方法，
会在以后的文章中结合实例具体慢慢介绍。
首先要明确的是，scikit-learn提供了算法().get_params()方法来查看每个算法可以调整的参数，
比如说，我们想查看SVM分类器算法可以调整的参数，可以：
SVC().get_params()
输出的就是SVM算法可以调节的参数以及系统默认的参数值。每个参数的具体含义会在以后的文章中介绍。
{'C': 1.0,
'cache_size': 200,
'class_weight': None,
'coef0': 0.0,
'decision_function_shape': 'ovr',
'degree': 3,
'gamma': 'auto',
'kernel': 'rbf',
'max_iter': -1,
'probability': False,
'random_state': None,
'shrinking': True,
'tol': 0.001,
'verbose': False}


from sklearn.model_selection import cross_val_score,GridSearchCV
from sklearn.算法位置 import 算法名
 
模型名 = SVC()
 
params = [
        {'模型参数1': [选择1，选择2，选择3],'模型参数2': [选择1，选择2，选择3]},
        {'模型参数1': [选择1，选择2],'模型参数2': [选择1，选择2]}
                        ...... ..... ......
        ]

best_model = GridSearchCV(模型名, param_grid=params,cv = 5,scoring = 'accuracy')
best_model.fit(train_x,train_y)

看到这里，可能有人会有疑惑：为什么要采用列表、字典、列表三层嵌套的方式呢？params直接是字典的形式不行吗？答案是：行，但是不好。

让我们先算一个小的数学题：假如我们要调节n个参数，每个参数有4个备选值。那么程序就会训练  。当n为10的时候， ，这是一个对于计算机来说庞大的计算量。而当我们将这10个参数拆分成5组，每次只调节两个参数，其他参数采用默认值，那么计算量就是  ，计算量会大大减少。

列表的作用这是如此，保证了每次只调节列表中的一个字典中的参数。

运行之后，best_model就是我们得到的最优模型，可以利用这个模型进行预测。

当然，best_model 还有好多好用的属性：

best_model.cv_results_：可以查看不同参数情况下的评价结果。

best_model.param_ :得到该模型的最优参数

best_model.best_score_: 得到该模型的最后评分结果
"""

#实现SVM分类器
###1、svm分类器
SVM3="""from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.svm import SVC

svm_model = SVC()

params = [
    {'kernel': ['linear'], 'C': [1, 10, 100, 100]},
    {'kernel': ['poly'], 'C': [1], 'degree': [2, 3]},
    {'kernel': ['rbf'], 'C': [1, 10, 100, 100], 'gamma': [1, 0.1, 0.01, 0.001]}
]

best_model = GridSearchCV(svm_model, param_grid=params, cv=5, scoring='accuracy')
best_model.fit(train_x, train_y)
查看最优得分：
best_model.best_score_
查看最优参数：
best_model.best_params_
查看最优模型的所有参数：
best_model.best_estimator_
查看每个参数的交叉验证结果：
best_model.cv_results_

注：
1、以前版本是best_model.grid_scores_，现在已经移除
2、这个函数输出很多数据，不方便查看，一般不用
在实际使用中，如果计算资源够用，一般采用第三种万能公式。如果，为了节约计算资源尽快算出结果，
也会采用以后介绍的手动调参方式。
当然，本文为了说明万能模板的使用方法，在Iris数据集上将所有算法都实现了一遍，
在实际应用中，如果项目时间紧急，根据自己的需求和数据量级选择一个合适的算法使用即可。
具体怎么选择，scikit-learn官方非常贴心地画了一个图，
供大家根据数据量和算法类型选择合适的模型，这副图建议收藏：
"""








# 通用的预处理框架  
  
import pandas as pd  
import numpy as np  
import scipy as sp  
  
# 文件读取  
def read_csv_file(f, logging=False):  
    print("==========读取数据=========")  
    data =  pd.read_csv(f)  
    if logging:  
        print(data.head(5))  
        print(f, "包含以下列")  
        print(data.columns.values)  
        print(data.describe())  
        print(data.info())  
    return data  
 
 
 
# 通用的LogisticRegression框架  
  
import pandas as pd  
import numpy as np  
from scipy import sparse  
from sklearn.preprocessing import OneHotEncoder  
from sklearn.linear_model import LogisticRegression  
from sklearn.preprocessing import StandardScaler  
  
# 1. load data  
df_train = pd.DataFrame()  
df_test  = pd.DataFrame()  
y_train = df_train['label'].values  
  
# 2. process data  
ss = StandardScaler()  
  
  
# 3. feature engineering/encoding  
# 3.1 For Labeled Feature  
enc = OneHotEncoder()  
feats = ["creativeID", "adID", "campaignID"]  
for i, feat in enumerate(feats):  
    x_train = enc.fit_transform(df_train[feat].values.reshape(-1, 1))  
    x_test = enc.fit_transform(df_test[feat].values.reshape(-1, 1))  
    if i == 0:  
        X_train, X_test = x_train, x_test  
    else:  
        X_train, X_test = sparse.hstack((X_train, x_train)), sparse.hstack((X_test, x_test))  
  
# 3.2 For Numerical Feature  
# It must be a 2-D Data for StandardScalar, otherwise reshape(-1, len(feats)) is required  
feats = ["price", "age"]  
x_train = ss.fit_transform(df_train[feats].values)  
x_test  = ss.fit_transform(df_test[feats].values)  
X_train, X_test = sparse.hstack((X_train, x_train)), sparse.hstack((X_test, x_test))  
  
# model training  
lr = LogisticRegression()  
lr.fit(X_train, y_train)  
proba_test = lr.predict_proba(X_test)[:, 1]  



 LightGBM
1. 二分类
import lightgbm as lgb
import pandas as pd
import numpy as np
import pickle
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
 
print("Loading Data ... ")
 
# 导入数据
train_x, train_y, test_x = load_data()
 
# 用sklearn.cross_validation进行训练数据集划分，这里训练集和交叉验证集比例为7：3，可以自己根据需要设置
X, val_X, y, val_y = train_test_split(
    train_x,
    train_y,
    test_size=0.05,
    random_state=1,
    stratify=train_y ## 这里保证分割后y的比例分布与原数据一致
)
 
X_train = X
y_train = y
X_test = val_X
y_test = val_y
 
 
# create dataset for lightgbm
lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)
# specify your configurations as a dict
params = {
    'boosting_type': 'gbdt',
    'objective': 'binary',
    'metric': {'binary_logloss', 'auc'},
    'num_leaves': 5,
    'max_depth': 6,
    'min_data_in_leaf': 450,
    'learning_rate': 0.1,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.95,
    'bagging_freq': 5,
    'lambda_l1': 1,  
    'lambda_l2': 0.001,  # 越小l2正则程度越高
    'min_gain_to_split': 0.2,
    'verbose': 5,
    'is_unbalance': True
}
 
# train
print('Start training...')
gbm = lgb.train(params,
                lgb_train,
                num_boost_round=10000,
                valid_sets=lgb_eval,
                early_stopping_rounds=500)
 
print('Start predicting...')
 
preds = gbm.predict(test_x, num_iteration=gbm.best_iteration)  # 输出的是概率结果
 
# 导出结果
threshold = 0.5
for pred in preds:
    result = 1 if pred > threshold else 0
 
# 导出特征重要性
importance = gbm.feature_importance()
names = gbm.feature_name()
with open('./feature_importance.txt', 'w+') as file:
    for index, im in enumerate(importance):
        string = names[index] + ', ' + str(im) + '\n'
        file.write(string)
        


2. 多分类
import lightgbm as lgb
import pandas as pd
import numpy as np
import pickle
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
 
print("Loading Data ... ")
 
# 导入数据
train_x, train_y, test_x = load_data()
 
# 用sklearn.cross_validation进行训练数据集划分，这里训练集和交叉验证集比例为7：3，可以自己根据需要设置
X, val_X, y, val_y = train_test_split(
    train_x,
    train_y,
    test_size=0.05,
    random_state=1,
    stratify=train_y ## 这里保证分割后y的比例分布与原数据一致
)
 
X_train = X
y_train = y
X_test = val_X
y_test = val_y
 
 
# create dataset for lightgbm
lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)
# specify your configurations as a dict
params = {
    'boosting_type': 'gbdt',
    'objective': 'multiclass',
    'num_class': 9,
    'metric': 'multi_error',
    'num_leaves': 300,
    'min_data_in_leaf': 100,
    'learning_rate': 0.01,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'lambda_l1': 0.4,
    'lambda_l2': 0.5,
    'min_gain_to_split': 0.2,
    'verbose': 5,
    'is_unbalance': True
}
 
# train
print('Start training...')
gbm = lgb.train(params,
                lgb_train,
                num_boost_round=10000,
                valid_sets=lgb_eval,
                early_stopping_rounds=500)
 
print('Start predicting...')
 
preds = gbm.predict(test_x, num_iteration=gbm.best_iteration)  # 输出的是概率结果
 
# 导出结果
for pred in preds:
    result = prediction = int(np.argmax(pred))
 
# 导出特征重要性
importance = gbm.feature_importance()
names = gbm.feature_name()
with open('./feature_importance.txt', 'w+') as file:
    for index, im in enumerate(importance):
        string = names[index] + ', ' + str(im) + '\n'
        file.write(string)
        
XGBoost
1. 二分类
import numpy as np
import pandas as pd
import xgboost as xgb
import time
from sklearn.model_selection import StratifiedKFold
 
 
from sklearn.model_selection import train_test_split
train_x, train_y, test_x = load_data()
 
# 构建特征
 
 
# 用sklearn.cross_validation进行训练数据集划分，这里训练集和交叉验证集比例为7：3，可以自己根据需要设置
X, val_X, y, val_y = train_test_split(
    train_x,
    train_y,
    test_size=0.01,
    random_state=1,
    stratify=train_y
)
 
# xgb矩阵赋值
xgb_val = xgb.DMatrix(val_X, label=val_y)
xgb_train = xgb.DMatrix(X, label=y)
xgb_test = xgb.DMatrix(test_x)
 
# xgboost模型 #####################
 
params = {
    'booster': 'gbtree',
    # 'objective': 'multi:softmax',  # 多分类的问题、
    # 'objective': 'multi:softprob',   # 多分类概率
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    # 'num_class': 9,  # 类别数，与 multisoftmax 并用
    'gamma': 0.1,  # 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。
    'max_depth': 8,  # 构建树的深度，越大越容易过拟合
    'alpha': 0,   # L1正则化系数
    'lambda': 10,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。
    'subsample': 0.7,  # 随机采样训练样本
    'colsample_bytree': 0.5,  # 生成树时进行的列采样
    'min_child_weight': 3,
    # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言
    # ，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。
    # 这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。
    'silent': 0,  # 设置成1则没有运行信息输出，最好是设置为0.
    'eta': 0.03,  # 如同学习率
    'seed': 1000,
    'nthread': -1,  # cpu 线程数
    'missing': 1,
    'scale_pos_weight': (np.sum(y==0)/np.sum(y==1))  # 用来处理正负样本不均衡的问题,通常取：sum(negative cases) / sum(positive cases)
    # 'eval_metric': 'auc'
}
plst = list(params.items())
num_rounds = 2000  # 迭代次数
watchlist = [(xgb_train, 'train'), (xgb_val, 'val')]
 
# 交叉验证
result = xgb.cv(plst, xgb_train, num_boost_round=200, nfold=4, early_stopping_rounds=200, verbose_eval=True, folds=StratifiedKFold(n_splits=4).split(X, y))
 
# 训练模型并保存
# early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练
model = xgb.train(plst, xgb_train, num_rounds, watchlist, early_stopping_rounds=200)
model.save_model('../data/model/xgb.model')  # 用于存储训练出的模型
 
preds = model.predict(xgb_test)
 
# 导出结果
threshold = 0.5
for pred in preds:
    result = 1 if pred > threshold else 0
    
Keras
1. 二分类
import numpy as np
import pandas as pd
import time
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
 
from keras.models import Sequential
from keras.layers import Dropout
from keras.layers import Dense, Activation
from keras.utils.np_utils import to_categorical
 
# coding=utf-8
from model.util import load_data as load_data_1
from model.util_combine_train_test import load_data as load_data_2
from sklearn.preprocessing import StandardScaler # 用于特征的标准化
from sklearn.preprocessing import Imputer
 
print("Loading Data ... ")
# 导入数据
train_x, train_y, test_x = load_data()
 
# 构建特征
X_train = train_x.values
X_test  = test_x.values
y = train_y
 
imp = Imputer(missing_values='NaN', strategy='mean', axis=0)
X_train = imp.fit_transform(X_train)
 
sc = StandardScaler()
sc.fit(X_train)
X_train = sc.transform(X_train)
X_test  = sc.transform(X_test)
 
 
model = Sequential()
model.add(Dense(256, input_shape=(X_train.shape[1],)))
model.add(Activation('tanh'))
model.add(Dropout(0.3))
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.3))
model.add(Dense(512))
model.add(Activation('tanh'))
model.add(Dropout(0.3))
model.add(Dense(256))
model.add(Activation('linear'))
model.add(Dense(1)) # 这里需要和输出的维度一致
model.add(Activation('sigmoid'))
 
# For a multi-class classification problem
model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
 
epochs = 100
model.fit(X_train, y, epochs=epochs, batch_size=2000, validation_split=0.1, shuffle=True)
 
# 导出结果
threshold = 0.5
for index, case in enumerate(X_test):
    case =np.array([case])
    prediction_prob = model.predict(case)
    prediction = 1 if prediction_prob[0][0] > threshold else 0
    
2. 多分类
import numpy as np
import pandas as pd
import time
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
 
from keras.models import Sequential
from keras.layers import Dropout
from keras.layers import Dense, Activation
from keras.utils.np_utils import to_categorical
 
# coding=utf-8
from model.util import load_data as load_data_1
from model.util_combine_train_test import load_data as load_data_2
from sklearn.preprocessing import StandardScaler # 用于特征的标准化
from sklearn.preprocessing import Imputer
 
print("Loading Data ... ")
# 导入数据
train_x, train_y, test_x = load_data()
 
# 构建特征
X_train = train_x.values
X_test  = test_x.values
y = train_y
 
# 特征处理
sc = StandardScaler()
sc.fit(X_train)
X_train = sc.transform(X_train)
X_test  = sc.transform(X_test)
y = to_categorical(y) ## 这一步很重要，一定要将多类别的标签进行one-hot编码
 
 
model = Sequential()
model.add(Dense(256, input_shape=(X_train.shape[1],)))
model.add(Activation('tanh'))
model.add(Dropout(0.3))
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.3))
model.add(Dense(512))
model.add(Activation('tanh'))
model.add(Dropout(0.3))
model.add(Dense(256))
model.add(Activation('linear'))
model.add(Dense(9)) # 这里需要和输出的维度一致
model.add(Activation('softmax'))
 
# For a multi-class classification problem
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
 
epochs = 200
model.fit(X_train, y, epochs=epochs, batch_size=200, validation_split=0.1, shuffle=True)
 
# 导出结果
for index, case in enumerate(X_test):
    case = np.array([case])
    prediction_prob = model.predict(case)
    prediction = np.argmax(prediction_prob)
    
    
    
    
    
    
处理正负样本不均匀的案例
有些案例中，正负样本数量相差非常大，数据严重unbalanced，这里提供几个解决的思路
# 计算正负样本比例
positive_num = df_train[df_train['label']==1].values.shape[0]
negative_num = df_train[df_train['label']==0].values.shape[0]
print(float(positive_num)/float(negative_num))

主要思路
1. 手动调整正负样本比例
2. 过采样 Over-Sampling
对训练集里面样本数量较少的类别（少数类）进行过采样，合成新的样本来缓解类不平衡，比如SMOTE算法
3. 欠采样 Under-Sampling
4. 将样本按比例一一组合进行训练，训练出多个弱分类器，最后进行集成



排序算法
def quick_sort(a,l,r):
	if(l>=r):
		return 
	key = a[l]
	i,j = l-1,r+1
	while(i<j):
		i+=1
		j-=1
		while(a[j]>key):
			j-=1
		while(a[i]<key):
			i+=1
		if(i<j):
			temp = a[i]
			a[i] = a[j]
			a[j] = temp
	quick_sort(a,l,j)
	quick_sort(a,j+1,r)
  
  
  归并排序
  def merge_sort(a,temp,l,r):
	if(l>=r):
		return
	mid = (r+l)//2
	merge_sort(a,temp,l,mid)
	merge_sprt(a,temp,mid+1,r)
	
	k = 0
	while(i<=mid and j<=r):
		if(a[i]<a[j]):
			temp[k] = a[i]
			i+=1
		else:
			temp[k] = a[j]
			j+=1
		k+=1
		
	while(i<=mid):
		temp[k] = a[i]
		k+=1
		i+=1
	while(j<=r):
		temp[k] = a[j]
		j+=1
		k+=1
	
	k = 0
	i = l
	while(i<=r):
		a[i] = temp[k]
		k+=1
		i+=1



KMP算法
def getNe(s):
	"""
	求取next数组
	"""
	m = len(s)
	#数组取大一点是没有关系的
	next = [0 for _ in range(m+10)]
	i = 1
	j = 0
	while(i<m):
		while(j>0 and s[i]!=s[j]):
			j = next[j-1]
		if(s[i]==s[j]);
			j+=1
		next[i] = j
		i+=1
	return next


def KMP(s1,s2):
	"""
	返回第x个字符之后会匹配上
	"""
	next = getNe(s2)
	m_s1 = len(s1)
	m_s2 = len(s2)
	
	i = 0
	j = 0
	while(i<m_s1):
		while(j>0 and s1[i]!=s2[j]):
			j = next[j-1]
		if(s1[i]==s2[j]):
			j+=1
		if(j==m_s2):
			return i - m_s2 + 1
		i+=1
	return -1


Floyd 算法
def Floyd(g):

    for k in range(1,100):
        for i in range(1,100):
            for j in range(1,100):
                g[i][j] = min(g[i][k]+g[k][j],g[i][j])
                
                
Dijkstra 算法
def Dijkstra(g):
	st = [False for _ in range(n+1)]
	dist = [float("inf") for _ in range(n+1)]
	dist[1] = 0
	for i in range(n-1):
		t = -1
		for j in range(1,n+1):
			if(not st[j] and (t==-1 or dist[t]>dist[j]):
				t = j 
		
		for j in range(1,n+1);
			dist[j] = min(dist[j],dist[t]+g[t][j])
	if(dist[n]==float("inf")):
		return False



BellMan-Ford 算法
class node:
	a = None
	b = None
	c = None
Nodes = [node(a,b,c) for _ in range(m)]

def BellmanFord():
	dist = [float("inf") for _ in range(1,n+1)]
	dist[i] = 0
	for i in range(n):
		for j in range(m);
			a,b,w = Nodes[j].a,Nodes[j].b,Nodes[j].c
			dist[b] = min(dist[b],dist[a]+w)


SPFA 算法

def SPFA():
	import collections
	q = collections.deque()
	dist = [float("inf") for _ in range(n)]
	st = [False for _ in range(n)]

	q.append(1)
	st[1]=True
	while(len(q)):
		t = q.pop()
		st[t] = False
		i = h[t]
		while(i!=-1):
			j = e[i]
			if(dist[j]>dist[t]+w[i]):
				dist[j] = dist[t]+w[i]
				if(not st[j]):
					q.append(j)
					st[j] = True
			i = ne[i]
	# 这个自己取一个比较大的数
 	if(dist[n]>=100000):
 		return False


Prim 算法

def Prime(g):
    """
    这里的话还是使用邻接矩阵的
    :return:
    """
    dist = [float("inf") for _ in range(100)]
    st = [False for _ in range(100)]
    res = 0
    for i in range(100):

        t = -1
        for j in range(1,101):
            if((t == -1 and not st[j]) or dist[t]>dist[j]):
                t = j

        if(i and dist[t] == float("inf")):
            return float("inf")

        if(i):
            res+=dist[t]

        for j in range(100):
            dist[j] = min(dist[j],g[t][j])


Kruskra 算法

def Kruskra():
    """
    定义这个数据是存储边的
    :return:
    """
    # 这个P的话就是Parents数组
    p = [0]
    res = 0
    cnt = 0
    Nodes = [Node() for _ in range(100)]
    sorted(Nodes,lambda node:node.c)
    for i in range(100):
        node = Nodes[i]
        a = find(node.a,p)
        b = find(node.b,p)
        if(a!=b):
            p[a] = b
            res+=node.c
            cnt+=1
        #此时是不连通的
        if(cnt<100-1):
            return float("inf")


染色法

"""
0 表示没有染色，1表示白色，2表示黑色
"""

def upColor(color,a,c):
	color[a] = c
	i = h[a]
	while(i!=-1):
		j = e[i]
		if(not color[j]):
			if(not upColor(st,j,3-c)):
				return False
		elif(color[j]==c):
			return False
		i = ne[i]
	return True

def check():
	
	for i in range(1,n+1):
		if(not upColor(st,i,1)):
			return False
	return True
  
  
  
  Hunger算法
  def Match(st,match,a):
	
	i = h[a]
    while(i!=-1):
        j = e[i]
        if(not st[j]):
            st[j] = True
            if(match[j]==0 or Match(st,match,j)):
                match[j] = a
                return True
        i = ne[i]
	return False

def Hunager():

	res = 0 #匹配个数
	Match = [0 for _ in range(10000)] #右侧的集合元素和左侧的谁进行了匹配
	for i in range(1,n1+1):
		# 表示右边的那个集合元素有没有匹配到
		st = [False for _ in range(10000)]
		if(Match(st,match,i)):
			res+=1
	return res
		
	一、二分模板
题目地址

题目：给你一个 m * n 的矩阵 grid，矩阵中的元素无论是按行还是按列，都以非递增顺序排列。 

请你统计并返回 grid 中 负数 的数目。

思路：找到每排的第一个负数，后面就都是负数了，最后累计负数数目

模板：
def binary_search(nums, target):
    low = 0
    high = len(nums) - 1
    while low <= high:
        mid = (low + high) // 2
 
        if nums[mid] == target:
            return mid
        if nums[mid] > target:
            high = mid - 1
        else:
            low = mid + 1
    return low
 
 
a = [1, 3, 7, 9, 14, 20, 24]
print(binary_search(a, 0))  # 0
print(binary_search(a, 1))  # 0
print(binary_search(a, 2))  # 1
print(binary_search(a, 4))  # 2
print(binary_search(a, 8))  # 3
 
print(binary_search(a, 11))  # 4
print(binary_search(a, 16))  # 5
print(binary_search(a, 24))  # 6
print(binary_search(a, 29))  # 7



from typing import List
 
 
class Solution:
    def countNegatives(self, grid: List[List[int]]) -> int:
        res = 0
        m = grid.__len__()
        n = grid[0].__len__()
        for i in range(m):
            # 二分找到0的位置
            low, high = 0, n - 1
            while low < high:
                mid = (low + high) // 2
                if grid[i][mid] >= 0:
                    low = mid + 1
                else:
                    high = mid
 
            if grid[i][low] < 0:
                res += n - low
        return res
 
 
s = Solution()
print(s.countNegatives([[4, 3, 2, -1], [3, 2, 1, -1], [1, 1, -1, -2], [-1, -1, -2, -3]]))
# 8

二、递归模板
题目地址

题目：

在经典汉诺塔问题中，有 3 根柱子及 N 个不同大小的穿孔圆盘，盘子可以滑入任意一根柱子。一开始，所有盘子自上而下按升序依次套在第一根柱子上(即每一个盘子只能放在更大的盘子上面)。移动圆盘时受到以下限制:
(1) 每次只能移动一个盘子;
(2) 盘子只能从柱子顶端滑出移到下一根柱子;
(3) 盘子只能叠在比它大的盘子上。

请编写程序，用栈将所有盘子从第一根柱子移到最后一根柱子。

你需要原地修改栈。

思路：

将N个盘子分为N，N-1两部分，将N-1个盘子看成一个整体，分三步完成移动即可完成

1. N-1部分由A->B

2. N部分由A->C

3. N-1部分由B->C

再把上述N-1部分分为N-1和N-2两部分，继续重复的分三步完成移动

模板：搞清楚递归退出条件是什么，问题怎么分解递归解决的
def fib(n):
    # 递归退出条件
    if n < 2:
        return n
    else:
        # 分解递归
        return fib(n-1) + fib(n-2)
 
print(fib(10))


class Solution:
    def hanota(self, A: List[int], B: List[int], C: List[int]) -> None:
        def hanoi(n,a,b,c):
            # 递归退出条件
            if n == 1:
                c.append(a.pop())
            else:
                # 分解递归
                hanoi(n-1,a,c,b)
                c.append(a.pop())
                hanoi(n-1,b,a,c)
 
        hanoi(len(A),A,B,C)
        
        
二叉树遍历模板
# 前序优先遍历
def qianxu(p: TreeNode):
    res = []
    stack = []
    while (stack.__len__() != 0 or p):
        if p:
            res.append(p.val)
            stack.append(p)
            p = p.left
        else:
            p = stack.pop(-1)
            p = p.right
    return res
 
 
# 中序优先遍历
def zhongxu(p: TreeNode):
    res = []
    stack = []
    while (stack.__len__() != 0 or p):
        if p:
            stack.append(p)
            p = p.left
        else:
            p = stack.pop(-1)
            res.append(p.val)
            p = p.right
    return res
 
 
# 后序优先遍历
def houxu(p: TreeNode):
    res = []
    stack = []
    d = dict()
    while (p or stack.__len__() != 0):
        if p:
            stack.append(p)
            d.update({p.val: 1})
            p = p.left
        else:
            p = stack[-1]
            if d[p.val] == 2:
                stack.pop(-1)
                res.append(p.val)
                p = None
            else:
                d[p.val] = 2
                p = p.right
 
    return res
 
def houxu2( root):
    '''
    利用两个栈实现
    '''
    s1 = []
    s2 = []
    s1.append( root )
    while s1:
        node = s1.pop()
        s2.append( node )
        if node.lchild:
            s1.append( node.lchild )
        if node.rchild:
            s1.append( node.rchild )
    while s2:
        print(s2.pop().value)
 
# 层次遍历，用队列
def cengci(p: TreeNode):
    res = []
    queue = [p]
    while (queue.__len__() != 0):
        p = queue.pop(0)
        res.append(p.val)
        if p.left:
            queue.append(p.left)
        if p.right:
            queue.append(p.right)
    return res
 
# 递归
# 先序
def preorder(root):
    if not root:
        return 
    print(root.val)
    preorder(root.left)
    preorder(root.right) 
# 中序
def inorder(root):
    if not root:
        return 
    inorder(root.left)
    print(root.val)
    inorder(root.right)
# 后序
def postorder(root):
    if not root:
        return 
    postorder(root.left)
    postorder(root.right)
    print(root.val)
    
    
    def exists(self, idx: int, d: int, node: TreeNode) -> bool:
        """
        Last level nodes are enumerated from 0 to 2**d - 1 (left -> right).
        Return True if last level node idx exists. 
        Binary search with O(d) complexity.
        """
        left, right = 0, 2**d - 1
        for _ in range(d):
            pivot = (left + right) // 2
            if idx <= pivot:
                node = node.left
                right = pivot
            else:
                node = node.right
                left = pivot + 1
        return node is not None

递归--代码模板
def recursion(level, param1, param2, ...): 
    # recursion terminator 
    if level > MAX_LEVEL: 
    process_result 
    return 
    # process logic in current level 
    process(level, data...) 
    # drill down 
    self.recursion(level + 1, p1, ...) 
    # reverse the current level status if needed
    
    
   
